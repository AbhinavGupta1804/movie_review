{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one_hot function in TensorFlow Keras converts words into integer indices by mapping them to a fixed vocabulary size using hashing.\n",
    "\n",
    "text -> vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]\n",
    "sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in numbers ka matlab h ki , glass of sentence 1 or any other  will result\n",
    " 1 in 6775th index & rest 9999 will be zero\n",
    " \n",
    " one_hot(words, voc_size) → expects a single string (sentence) as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5157, 482, 6065, 4753],\n",
       " [5157, 482, 6065, 5417],\n",
       " [5157, 8128, 6065, 347],\n",
       " [8649, 35, 2586, 729, 3217],\n",
       " [8649, 35, 2586, 729, 6503],\n",
       " [2925, 5157, 9429, 6065, 8874],\n",
       " [6068, 4617, 3553, 729]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define the vocabulary size\n",
    "voc_size=10000\n",
    "### One Hot Representation\n",
    "one_hot_repr=[one_hot(words,voc_size)for words in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad_sequences makes all lists the same length by adding zeros or cutting extra values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 5157  482 6065 4753]\n",
      " [   0    0    0    0 5157  482 6065 5417]\n",
      " [   0    0    0    0 5157 8128 6065  347]\n",
      " [   0    0    0 8649   35 2586  729 3217]\n",
      " [   0    0    0 8649   35 2586  729 6503]\n",
      " [   0    0    0 2925 5157 9429 6065 8874]\n",
      " [   0    0    0    0 6068 4617 3553  729]]\n"
     ]
    }
   ],
   "source": [
    "## word Embedding Representation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "#from tensorflow.keras.processing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import pad_sequences                 \n",
    "from tensorflow.keras.models import Sequential #sequential is must for every type of neural network\n",
    "import numpy as np\n",
    "sent_length=8  #max length  #list name       \n",
    "embedded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=sent_length) #post se aage 0 add honge\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of MODEL: Converts words (integers) into dense vector representations before feeding into the model.\n",
    "If before a word was a 10,000-dim one-hot vector, after embedding it becomes a 10-dim dense vector.\n",
    "\n",
    "matlab first these 10 dimensions are randomly initialised , and then we update these 10 elements of vector with the help of back propagation\n",
    "\n",
    "These 10-dim dense vectors are learned representations that capture semantic meaning — i.e., similar words get similar vectors (e.g., \"king\" and \"queen\").\n",
    "\n",
    "The model uses **word indices** (numbers) to fetch **embedding vectors** from an embedding matrix, instead of using large, sparse **one-hot vectors**. This is more efficient and helps the model learn better word meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhi1\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## feature representation\n",
    "dim=10                    # Each word in the vocabulary will be converted into a 10-dimensional vector.\n",
    "model=Sequential()                                           # Initializes a sequential model.\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length))  # Expected sentence length (i.e., how many words per input).\n",
    "model.compile('adam','mse')   \n",
    "model.summary()\n",
    "#Uses Adam optimizer for training.\n",
    "# Mean Squared Error (MSE) as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00127659, -0.01866531, -0.04405781,  0.00346626,\n",
       "          0.03091947,  0.00297161, -0.03637736, -0.01783059,\n",
       "          0.03567885,  0.02222336],\n",
       "        [ 0.03851828,  0.04706664,  0.00856987, -0.02980471,\n",
       "         -0.02187045,  0.01102706, -0.04920062,  0.04284799,\n",
       "         -0.02777903,  0.04258044],\n",
       "        [ 0.01992457, -0.0197791 , -0.01805289, -0.02786139,\n",
       "         -0.00908253,  0.04555324, -0.01049085, -0.02507603,\n",
       "         -0.04187321, -0.00729544],\n",
       "        [-0.017657  , -0.02614006,  0.03707941, -0.02908678,\n",
       "         -0.00118549, -0.02354999, -0.00508617, -0.04659992,\n",
       "         -0.01311654,  0.01269079]],\n",
       "\n",
       "       [[ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00127659, -0.01866531, -0.04405781,  0.00346626,\n",
       "          0.03091947,  0.00297161, -0.03637736, -0.01783059,\n",
       "          0.03567885,  0.02222336],\n",
       "        [ 0.03851828,  0.04706664,  0.00856987, -0.02980471,\n",
       "         -0.02187045,  0.01102706, -0.04920062,  0.04284799,\n",
       "         -0.02777903,  0.04258044],\n",
       "        [ 0.01992457, -0.0197791 , -0.01805289, -0.02786139,\n",
       "         -0.00908253,  0.04555324, -0.01049085, -0.02507603,\n",
       "         -0.04187321, -0.00729544],\n",
       "        [ 0.00228047, -0.03167176,  0.02501528, -0.03113624,\n",
       "          0.04828859,  0.04941113, -0.04664434, -0.0462876 ,\n",
       "         -0.03603216,  0.01698237]],\n",
       "\n",
       "       [[ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00127659, -0.01866531, -0.04405781,  0.00346626,\n",
       "          0.03091947,  0.00297161, -0.03637736, -0.01783059,\n",
       "          0.03567885,  0.02222336],\n",
       "        [ 0.03177511,  0.00293027, -0.02732818, -0.01503334,\n",
       "         -0.03009589,  0.00095142,  0.02869755,  0.00576748,\n",
       "         -0.03507692, -0.00755601],\n",
       "        [ 0.01992457, -0.0197791 , -0.01805289, -0.02786139,\n",
       "         -0.00908253,  0.04555324, -0.01049085, -0.02507603,\n",
       "         -0.04187321, -0.00729544],\n",
       "        [ 0.03041825, -0.03660749, -0.02324318, -0.04321228,\n",
       "          0.03487792, -0.03911583, -0.03296893,  0.01723194,\n",
       "          0.03122249, -0.00345628]],\n",
       "\n",
       "       [[ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.04378569,  0.01771435, -0.01238408,  0.03056509,\n",
       "         -0.02380304, -0.04377515, -0.02875951,  0.01583231,\n",
       "          0.03536144, -0.01096589],\n",
       "        [ 0.00124387, -0.01503856, -0.03443701,  0.03853769,\n",
       "         -0.01712314, -0.04591427, -0.01312329, -0.04654659,\n",
       "          0.01672739, -0.0410553 ],\n",
       "        [ 0.00301331, -0.00059577, -0.01650226, -0.04529121,\n",
       "         -0.0091335 , -0.00104464, -0.04504463,  0.0001962 ,\n",
       "         -0.03429911, -0.04405258],\n",
       "        [ 0.035503  , -0.02712115, -0.02541615,  0.00037556,\n",
       "         -0.004551  ,  0.0045873 ,  0.0167214 , -0.02268186,\n",
       "         -0.02234288,  0.02474164],\n",
       "        [ 0.0266819 ,  0.01789412,  0.0127793 , -0.01408286,\n",
       "          0.01633329, -0.04568479, -0.02973504,  0.01814449,\n",
       "          0.02784127, -0.03897472]],\n",
       "\n",
       "       [[ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.04378569,  0.01771435, -0.01238408,  0.03056509,\n",
       "         -0.02380304, -0.04377515, -0.02875951,  0.01583231,\n",
       "          0.03536144, -0.01096589],\n",
       "        [ 0.00124387, -0.01503856, -0.03443701,  0.03853769,\n",
       "         -0.01712314, -0.04591427, -0.01312329, -0.04654659,\n",
       "          0.01672739, -0.0410553 ],\n",
       "        [ 0.00301331, -0.00059577, -0.01650226, -0.04529121,\n",
       "         -0.0091335 , -0.00104464, -0.04504463,  0.0001962 ,\n",
       "         -0.03429911, -0.04405258],\n",
       "        [ 0.035503  , -0.02712115, -0.02541615,  0.00037556,\n",
       "         -0.004551  ,  0.0045873 ,  0.0167214 , -0.02268186,\n",
       "         -0.02234288,  0.02474164],\n",
       "        [ 0.04115829,  0.0341604 , -0.02886661,  0.03507216,\n",
       "         -0.02575147, -0.02040637, -0.01611654, -0.04029625,\n",
       "          0.00756846, -0.03177158]],\n",
       "\n",
       "       [[ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.02948222, -0.03746321,  0.00821725, -0.02567307,\n",
       "          0.01789255, -0.04152849,  0.0489229 ,  0.04736744,\n",
       "         -0.02647382,  0.01794881],\n",
       "        [ 0.00127659, -0.01866531, -0.04405781,  0.00346626,\n",
       "          0.03091947,  0.00297161, -0.03637736, -0.01783059,\n",
       "          0.03567885,  0.02222336],\n",
       "        [-0.03953798, -0.00515918, -0.02977669, -0.04655937,\n",
       "          0.04101603, -0.01523303,  0.00601346, -0.04898229,\n",
       "         -0.0206363 ,  0.00012342],\n",
       "        [ 0.01992457, -0.0197791 , -0.01805289, -0.02786139,\n",
       "         -0.00908253,  0.04555324, -0.01049085, -0.02507603,\n",
       "         -0.04187321, -0.00729544],\n",
       "        [-0.00367014, -0.01678884,  0.0269359 ,  0.0115797 ,\n",
       "          0.03871901,  0.01617697,  0.03828818, -0.00560021,\n",
       "         -0.00586933, -0.02008499]],\n",
       "\n",
       "       [[ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.00147997,  0.02197584,  0.02876599, -0.01417321,\n",
       "         -0.04609977, -0.01785077,  0.01445006, -0.02481191,\n",
       "         -0.03570934, -0.00948672],\n",
       "        [ 0.0471001 , -0.01497651,  0.02569569, -0.01334734,\n",
       "         -0.02926127,  0.03035373, -0.00571106, -0.00722624,\n",
       "         -0.00034561, -0.02681186],\n",
       "        [ 0.03167328,  0.01979581,  0.0314023 ,  0.00573986,\n",
       "          0.03238164,  0.03424741, -0.0339493 ,  0.04387588,\n",
       "         -0.02837961,  0.00133632],\n",
       "        [-0.02856796,  0.02102902,  0.0032519 , -0.00077188,\n",
       "          0.03925873,  0.03550886,  0.02450756, -0.00520047,\n",
       "         -0.01649011,  0.04910794],\n",
       "        [ 0.035503  , -0.02712115, -0.02541615,  0.00037556,\n",
       "         -0.004551  ,  0.0045873 ,  0.0167214 , -0.02268186,\n",
       "         -0.02234288,  0.02474164]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs) # 7 sentences -> 8 words  per sentence -> 10 dimensions per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0, 5157,  482, 6065, 4753], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0] #first sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line, `model.predict(embedded_docs[0])`, gives an error because `embedded_docs[0]` is a **1D array**, but the model expects a **2D array** (even for a single input). The model wants to receive a batch of inputs, so it expects the shape to be `(1, input_size)`.\n",
    "\n",
    "The second line, `model.predict(np.array([embedded_docs[0]]))`, works because it **wraps `embedded_docs[0]` in an additional array**, turning it into a 2D array with shape `(1, input_size)`, which is what the model expects.\n",
    "\n",
    "In short:\n",
    "- **1D array** (e.g., shape `(input_size,)`) → **error**\n",
    "- **2D array** (e.g., shape `(1, input_size)`) → **works**\n",
    "\n",
    "Let me know if that clears things up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.19.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict(embedded_docs[0])\n",
    "model.predict(np.array([embedded_docs[0]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
